{"cells":[{"cell_type":"markdown","metadata":{"id":"NHIlfa4t-APN"},"source":["# **텍스트 분류 모델 파인 튜닝하기**"]},{"cell_type":"markdown","metadata":{"id":"Y4lg_Qh1-APO"},"source":["# **1. 환경준비**"]},{"cell_type":"markdown","metadata":{"id":"xIsxZ4vq-APP"},"source":["## (1) 라이브러리 설치\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pYuF7bucv1Xi"},"outputs":[],"source":["!pip install transformers==4.31.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"by0at9QKKI0E"},"outputs":[],"source":["!pip install datasets"]},{"cell_type":"markdown","metadata":{"id":"QxxLadkDtAtY"},"source":["* 설치후 세션 재시작"]},{"cell_type":"markdown","metadata":{"id":"DjPiBeDitFmn"},"source":["## (2) 라이브러리 로딩"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K7TF5mqjtIaB"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from datasets import load_dataset  # 데이터셋 다운로드\n"]},{"cell_type":"markdown","metadata":{"id":"AWtwTFmltgZg"},"source":["## (3) 데이터셋 다운로드"]},{"cell_type":"markdown","metadata":{"id":"wDuVI2grt8Pi"},"source":["* emotions 데이터셋 소개\n","    * 트위터 글(텍스트) 기반의 감정 분류를 위한 데이터셋\n","    * 데이터셋 구조\n","        * text: 감정을 분석할 텍스트 데이터.\n","        * label: 'sadness', 'joy', 'love', 'anger', 'fear', 'surprise'\n","        * input_ids와 attention_mask: transformers 라이브러리와 함께 모델을 학습시킬 때 사용되는, 텍스트를 모델이 처리할 수 있는 형태로 인코딩한 값들입니다.\n","        * train 16,000건, val 2,000건, test 2,000건"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bAh8H53w-APQ"},"outputs":[],"source":["# emotion 데이터셋 다운로드\n","emotions = load_dataset(\"emotion\")\n","\n","# # 데이터 줄이기\n","# emotions[\"train\"] = emotions[\"train\"].shuffle(seed=42).select(range(10000))\n","# emotions[\"validation\"] = emotions[\"validation\"].shuffle(seed=42).select(range(1500))\n","# emotions[\"test\"] = emotions[\"test\"].shuffle(seed=42).select(range(1500))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CK4z9F7ntnm4"},"outputs":[],"source":["# 데이터 구조\n","emotions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1xNWw75It2uw"},"outputs":[],"source":["# 데이터 레이블\n","classes = emotions['train'].features['label'].names\n","classes"]},{"cell_type":"markdown","metadata":{"id":"vlinxgJCupNb"},"source":["# **2.데이터 둘러보기**"]},{"cell_type":"markdown","metadata":{"id":"M2DL7xyGusim"},"source":["## (1) 데이터 프레임으로 변환"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fa0fntKp-APR"},"outputs":[],"source":["# 데이터프레임으로 변환\n","emotions.set_format(type=\"pandas\")\n","\n","# train 데이터 만 추출\n","df = emotions[\"train\"][:]\n","\n","# 정수인코딩된 레이블에 원래 문자 추가하기\n","def label_int2str(row):\n","    return emotions[\"train\"].features[\"label\"].int2str(row)\n","\n","df[\"label_name\"] = df[\"label\"].apply(label_int2str)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"TDo6MI1vvzG0"},"source":["## (2) 클래스 분포 살펴보기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bma_QZf2waNP"},"outputs":[],"source":["df['label_name'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WShKG62s-APV"},"outputs":[],"source":["sns.countplot(x = 'label_name', data = df)\n","plt.grid()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"hSBbX3_p-APV"},"source":["## (3) 트윗 문장 길이(단어 수) 분포 확인\n","\n","* 트랜스포머 모델은 최대 문맥 길이라는 최대 입력 시퀀스 길이가 있음\n","* DistilBERT 는 최대 문맥 크기가 512 토큰.\n","* 토큰을 단어단위로 간주할 때, 트윗당 단어 분포"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DUMHNUt7xIJg"},"outputs":[],"source":["df[\"Words Per Tweet\"] = df[\"text\"].str.split().apply(len)\n","sns.histplot(x = 'Words Per Tweet', data = df, bins = 30)\n","plt.grid()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5kPIUSJM-APV"},"outputs":[],"source":["sns.kdeplot(x = 'Words Per Tweet', data = df, hue = 'label_name', common_norm = False)\n","plt.grid()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"woXI3GNjx8qm"},"source":["* 이제 더이상 데이터프레임 포멧이 필요하지 않으니 원본으로 되돌려 놓자."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9g2wFE1q-APV"},"outputs":[],"source":["emotions.reset_format()"]},{"cell_type":"markdown","metadata":{"id":"6eXubg1q-APW"},"source":["# **3.데이터 준비**"]},{"cell_type":"markdown","metadata":{"id":"Vd1XFpVg-APY"},"source":["* BERT에서 사용되는 토크나이즈 WordPiece\n","* AutoTokenizer 클래스 : 체크포인트 이름을 사용해 모델의 설정, 사전훈련된 가중치, 어휘사전을 자동으로 추출\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tWlSCfhM45aV"},"outputs":[],"source":["from transformers import AutoTokenizer"]},{"cell_type":"markdown","metadata":{"id":"eV3ExQbdzqu_"},"source":["## (1) 토크나이저 다운로드\n","* bert 모델 학습시 생성된 토크나이저 다운로드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sNhQnUFR-APY"},"outputs":[],"source":["model_ckpt = \"distilbert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"]},{"cell_type":"markdown","metadata":{"id":"Dv3HII236t-A"},"source":["* 모델 입력을 위한 필드 이름"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VhERdeo5-APZ"},"outputs":[],"source":["tokenizer.model_input_names"]},{"cell_type":"markdown","metadata":{"id":"l733eMPH-APZ"},"source":["## **(2) 데이터셋 토큰화**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dJBKZCZs-APZ"},"outputs":[],"source":["# 문장 하나씩 토크나이즈 하기 위한 함수 생성\n","def tokenize(batch):\n","    return tokenizer(batch[\"text\"], padding=True, truncation=True)"]},{"cell_type":"markdown","metadata":{"id":"Jw2dWNNJ792S"},"source":["* map 매서드는 말뭉치에 있는 모든 샘플을 개별적으로 적용."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fm1MFYI9-APZ"},"outputs":[],"source":["em_encoded = emotions.map(tokenize, batched=True, batch_size=None)"]},{"cell_type":"code","source":["emotions"],"metadata":{"id":"B0Z_o0H92iwd"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"otviBzW1-APZ"},"outputs":[],"source":["em_encoded"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uU6hA9dj1VpW"},"outputs":[],"source":["# 데이터 한건에 대한 내용을 살펴봅시다.\n","col_names = em_encoded[\"train\"].column_names\n","sample_data = em_encoded[\"train\"][0]\n","for i in col_names :\n","    print(i + ' :', sample_data[i])"]},{"cell_type":"markdown","metadata":{"id":"xXsfAtAq32RB"},"source":["## (3) 텐서플로 학습을 위한 데이터 구성"]},{"cell_type":"code","source":["em_encoded[\"train\"]"],"metadata":{"id":"TYQv85xe31lh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.model_input_names"],"metadata":{"id":"-kCzRXJL3_5z"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yBlsY9vj36Vg"},"outputs":[],"source":["# 학습 배치에 포함될 샘플의 수\n","batch_size = 64\n","\n","# 필요한 칼럼 : ['input_ids', 'attention_mask']\n","token_cols = tokenizer.model_input_names\n","\n","# 데이터셋 구성\n","train = em_encoded[\"train\"].to_tf_dataset(columns=token_cols, label_cols=\"label\",\n","                                          shuffle=True, batch_size=batch_size)\n","\n","val = em_encoded[\"validation\"].to_tf_dataset(columns=token_cols, label_cols=\"label\",\n","                                             shuffle=False, batch_size=batch_size)\n","\n","test = em_encoded[\"test\"].to_tf_dataset(columns=token_cols, label_cols=\"label\",\n","                                        shuffle=False, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"id":"QfJIC2_J-APa"},"source":["# **4.파인튜닝**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JgXLFkvu3fbn"},"outputs":[],"source":["from transformers import TFAutoModelForSequenceClassification\n","from sklearn.metrics import accuracy_score, f1_score\n","import tensorflow as tf\n","from keras.optimizers import Adam\n","from sklearn.metrics import *"]},{"cell_type":"markdown","metadata":{"id":"2mCZggUm-APf"},"source":["## **(1) 사전 훈련된 모델 로드하기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AFx46sA1GQht"},"outputs":[],"source":["# 사전훈련된 모델 지정\n","preTrModel = \"distilbert-base-uncased\"\n","\n","# Output Layer 노드 수\n","nclass = 6\n","\n","# 모델 로드하기\n","model_ft = TFAutoModelForSequenceClassification.from_pretrained(preTrModel, num_labels=nclass)"]},{"cell_type":"markdown","metadata":{"id":"sBpF1zM2-APg"},"source":["## **(2) 추가 학습**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bXlWLCjm-APi"},"outputs":[],"source":["# 컴파일 및 학습\n","model_ft.compile(optimizer = Adam(5e-5), loss = 'sparse_categorical_crossentropy')\n","model_ft.fit(train, validation_data = val, epochs=3, batch_size = 64)"]},{"cell_type":"markdown","metadata":{"id":"kFtWoSR5BQ_P"},"source":["## **(3) 예측 및 평가**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i4VdDa0G8LM_"},"outputs":[],"source":["pred = model_ft.predict(test)\n","pred = pred.logits.argmax(axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yVctWeZx8JaT"},"outputs":[],"source":["y_test = em_encoded[\"test\"]['label']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ltLB47CH74Jm"},"outputs":[],"source":["print(confusion_matrix(y_test, pred))\n","print()\n","print(classification_report(y_test, pred, target_names = classes))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"859V74m7BJ0y"},"outputs":[],"source":["def plot_confusion_matrix(y_true, y_pred, classes):\n","    cm = confusion_matrix(y_true, y_pred)\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n","    disp.plot(cmap=plt.cm.Blues, colorbar=False)\n","    plt.show()\n","\n","plot_confusion_matrix(y_test, pred, classes)"]},{"cell_type":"markdown","source":["# **5.모델 저장**"],"metadata":{"id":"faPQXLL0Dquv"}},{"cell_type":"markdown","source":["* 구글 드라이브에 모델 저장하기\n","    * 구글 드라이브 연결\n","    * 구글 드라이브에 fine_tuned 폴더 생성\n","    * 저장할 경로 지정 : /content/drive/MyDrive/fine_tuned/bert_emotions_fine_tuned\n","        * bert_emotions_fine_tuned 폴더를 생성하면서 하위에 필요한 파일들 저장"],"metadata":{"id":"_tMi9z7PF45b"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"2-wYlCXyC8Dm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lbKTZASaBJ3B"},"outputs":[],"source":["# model 저장하기\n","local_dir = '/content/drive/MyDrive/fine_tuned/bert_emotions_fine_tuned'\n","model_ft.save_pretrained(local_dir)\n","tokenizer.save_pretrained(local_dir)"]},{"cell_type":"markdown","source":["* 모델 저장 후, 허깅페이스에 업로드\n","    * 허깅페이스 회원가입\n","    * 새 모델을 눌러 저장소를 생성하고,\n","    * 구글 드라이브의 모델 파일들을 업로드"],"metadata":{"id":"aUEVnastFcse"}},{"cell_type":"markdown","source":["# **6.모델 사용**"],"metadata":{"id":"Sv_jQbtMFaPy"}},{"cell_type":"markdown","source":["* 허깅페이스에 등록된 모델은 pipeline을 통해 사용할 수 있습니다."],"metadata":{"id":"BKOOHrU5NCo9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"g7lBdS8kBJxx"},"outputs":[],"source":["from transformers import pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p65Lwp30BJvM"},"outputs":[],"source":["emotion_classifier = pipeline(task = 'text-classification',\n","                              model = 'hanky74/emotion_classification_based_distilbert01')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jayPDOq1BJrx"},"outputs":[],"source":["emotion_classifier('I am really happy today.')"]},{"cell_type":"code","source":["classes"],"metadata":{"id":"2HApLT3HE1p4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"J0HCByfzFCfe"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}